%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                         CHAPITRE 5                            %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\lhead[\fancyplain{}{\leftmark}]%Pour les pages paires \bfseries
      {\fancyplain{}{}} %Pour les pages impaires
\chead[\fancyplain{}{}]%
      {\fancyplain{}{}}
\rhead[\fancyplain{}{}]%Pour les pages paires 
      {\fancyplain{}{\rightmark}}%Pour les pages impaires \bfseries
\lfoot[\fancyplain{}{}]%
      {\fancyplain{}{}}
\cfoot[\fancyplain{}{\thepage}]%\bfseries
      {\fancyplain{}{\thepage}} %\bfseries
\rfoot[\fancyplain{}{}]%
     {\fancyplain{}{\scriptsize}}
     
\addto\captionsenglish{%
     \renewcommand\tablename{Table}    %Changement de Tab. en Tableau
   }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                      Start part here                          %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Accuracy assessment}
\label{ch:5}

%==============================================================================	Résumé du chapitre

\begin{center}
\rule{0.7\linewidth}{.5pt}
\begin{minipage}{0.7\linewidth}
\smallskip

\textit{After robustness, accuracy needs to be addressed. Two-dimensional deep-learning pose estimation algorithms can suffer from biases in joint pose localizations, which are reflected in triangulated coordinates, and then in 3D joint angle estimation. Pose2Sim, our robust markerless kinematics workflow, comes with a physically consistent OpenSim skeletal model, meant to mitigate these errors. \newline\newline
Its accuracy was concurrently validated against a reference marker-based method. Lower-limb joint angles were estimated over three tasks (walking, running, and cycling) performed multiple times by one participant. When averaged over all joint angles, the coefficient of multiple correlation (CMC) remained above 0.9 in the sagittal plane, except for the hip in running, which suffered from a systematic 15° offset (CMC = 0.65), and for the ankle in cycling, which was partially occluded (CMC = 0.75). When averaged over all joint angles and all degrees of freedom, mean errors were 3.0°, 4.1°, and 4.0°, in walking, running, and cycling, respectively; and range of motion errors were 2.7°, 2.3°, and 4.3°, respectively. Given the magnitude of error traditionally reported in joint angles computed from a marker-based optoelectronic system, Pose2Sim is deemed accurate enough for the analysis of lower-body kinematics in walking, cycling, and running.\newline\newline
This chapter is adapted from the article published in the Sensors: "Pose2Sim: An End-to-End Workflow for 3D Markerless Sports Kinematics—Part 2: Accuracy" \cite{Pagnon2022a}. See Figure~\ref{fig_visabstract3} for a visual abstract.
}

%\smallskip
\end{minipage}
\smallskip
\rule{0.7\linewidth}{.5pt}
\end{center}

\pagebreak
\minitoc

\vspace*{3cm}

\begin{figure}[hbtp]
	\centering
	\def\svgwidth{1\columnwidth}
	\fontsize{10pt}{10pt}\selectfont
	\includegraphics[width=\linewidth]{"../Intro/Figures/Fig_VisAbstract3.JPG"}
      \caption{Visual abstract for Pose2Sim accuracy assessment \cite{Pagnon2022a}.}
	\label{fig_visabstract3}
\end{figure}

\newpage


\section{Introduction}

Marker-based methods are often considered as the gold standard in motion analysis. Despite their accuracy, they bear several issues. Among others, marker placement hinders natural movement, and it is time-consuming. Therefore, markerless technologies are being examined to solve these issues. Among others, deep-learning based methods based on a network of calibrated RGB cameras are promising. They do not assume any particular environment, nor hinder the athlete’s movement and focus, and they are particularly robust (see previous chapter on \nameref{ch:4} \cite{Pagnon2021}). However, they require delicate calibration, large storage space, and high computational capacities. The technology, nevertheless, is still maturing and some light-weight systems such as BlazePose \cite{Bazarevsky2020} are being proposed, which can operate in real time on a mobile phone; however, they are still not quite as accurate as required for quantitative motion analysis \cite{Mroz2021}.

The most common evaluation metric for accuracy is the Mean Per Joint Position Error (MPJPE), which is the average Euclidian distance between the estimated joint coordinate and its ground truth. A large part of studies investigating 3D joint center estimation choose to triangulate the output of OpenPose \cite{Cao2019}. Their MPJPE usually lies between 30 and 40 mm \cite{Nakano2019,Slembrouck2020,Labuguen2020}. Ankle MPJPEs are within the margin of error of marker-based technologies (1–15 mm), whereas knee and hip MPJPEs are greater (30–50 mm). These errors are systematic and likely due to "ground-truth" images being mislabeled in the training dataset \cite{Needham2021b}. Triangulation from other 2D deep-learning algorithms (such as AlphaPose \cite{Fang2017} and DeepLabCut \cite{Mathis2018}) have also been compared \cite{Needham2021b}. AlphaPose results are similar to OpenPose’s; however, DeepLabCut errors are substantially higher.

Numerous studies have focused on the accuracy of 3D joint center estimation, but far fewer have examined 3D joint angle estimation. D’Antonio et al. computed direct flexion-extension angles for the lower limb from two cameras processed with OpenPose \cite{D'Antonio2021}. Range of Motion (ROM) errors lay between 2.8° and 14.1°. Wade et al. calculated frontal and sagittal knee and hip angles with OpenPose, AlphaPose, and DeepLabCut \cite{Wade2021}. They deemed the method accurate enough for assessing step length and velocity, but not for joint angle analysis. AniPose offers a toolkit for triangulating 2D poses from DeepLabCut \cite{Karashchuk2021}. To our knowledge, it has only been concurrently validated for index finger angles in the sagittal plane, resulting in a root-mean-square error of 7.5 degrees \cite{Geelen2021}. Theia, a commercially available software package for markerless analysis, uses its own patent-protected 2D pose estimator and triangulation procedure, and runs a skeletal model to constrain the results to physically consistent poses and movements \cite{Kanko2021b}. Their root-mean-square error (RMSE) compared to a marker-based method ranged between 2.6° and 13.2°.

We previously proposed our open-source solution, Pose2Sim (see \nameref{ch:3} \cite{Pagnon2022b}). It robustly triangulates OpenPose results \cite{Cao2019}, and leads to an OpenSim output \cite{Delp2007, Seth2018}. We showed that Pose2Sim was robust people in the background, to different sorts of mouvements (walking, running, and cycling), to dark and blurry images (0.5 gamma compression and 5.5 cm Gaussian blur), to 1 cm random calibration errors, and to using as few as four cameras (see previous chapter on \nameref{ch:4} \cite{Pagnon2021}). Now, the objective of this present study is to concurrently evaluate Pose2Sim’s lower-limb 3D accuracy, with a marker-based method, and on the same tasks.


\section{Methods}\label{sec:accuracy_methods}
\subsection{Data collection}

The same adult male participant as in the previous chapter on \nameref{ch:4} (1.89 m, 69 kg) was equipped with 83 reflective markers inspired from the CAST marker set \cite{Cappozzo1995}, composed of 35 anatomical markers, and 12 clusters of 4 markers (Figure~\ref{fig_mkmkl}). He was asked to perform three tasks: walking, running, and cycling, at a regular pace, back and forth across the capture space, following a regular pulsing sound (see previous chapter for further details). He provided his written consent prior to participating.

All tasks were performed in a room equipped with a green background for optimal segmentation of the subject with respect to the background, and 3D animated mesh extraction using a visual hull approach at each video frame \cite{Laurentini1994}. Twenty opto-electronic cameras captured the 3D coordinates of the markers, and 68 video cameras allowed retrieval of 3D textured meshes of the participant, which we subsequently placed in a virtual environment and filmed from 8 virtual cameras (Figure~\ref{fig_kinovis}). This gave us the opportunity to overlay our reflective markers, calculated joint centers, and OpenPose keypoints to the extracted mesh. This was particularly useful to correctly place OpenPose keypoints on the OpenSim model, i.e., with a systematic offset as regards true joint centers (\autoref{methods_details}). The acquisition was restricted in terms of 3D volume covered by both systems and data storage, resulting in the analysis of 8, 13, and 13 cycles of walking, running, and cycling, respectively. Once 3D point coordinates were retrieved, both systems underwent processes that were as close to each other as possible: coordinates were sampled at 30 Hz, then they were filtered with a 4th-order 6 Hz low-pass Butterworth filter (which efficiently filtered out noise without underestimating peak values, including in extremities); heel strikes were detected in both cases with the method proposed by \cite{Zeni2008}; stride duration was determined as the inverse of the frequency of the metronome followed by the participant; and inverse kinematics were optimized with the same OpenSim skeletal model.

\subsection{Markerless analysis}

All videos from our virtual cameras were processed by OpenPose (version 1.6), which delivered 2D joint coordinates for each view. We used the OpenPose experimental body\_25B model (Figure~\ref{fig_body25b}) with the highest accuracy parameters \cite{Hidalgo2021}. The Pose2Sim workflow was then used to track the person of interest, robustly triangulate the OpenPose 2D joint coordinates, and filter the resulting 3D coordinates. Then this output was fed to our OpenSim setup to constrain the results to physically consistent kinematics (more details in previous chapter). 

Pose2Sim comes with a generic OpenSim skeletal model, that has been slightly improved as regard to the previous chapter. It was adapted from the human gait full-body model \cite{Rajagopal2016} and the lifting full-body model \cite{Beaucage-Gauvreau2019}. While the spine of the gait model is represented as a single rigid bone, it is articulated in the lifting model, and each lumbar vertebra is constrained to the next one. This is more accurate for activities for which the spine is bent, such as cycling. However, the knee joint is more accurately defined in the gait model: abduction/adduction and internal/external rotation angles are constrained to the flexion/extension angle, whereas they are simply ignored in the lifting one. This also improves the estimation of knee flexion. All else being equal, as we want our model to be as versatile as possible, we used the spine definition of the lifting model, and the knee definition of the gait model. Since we did not investigate muscle-related issues, they were removed to decrease computation time. Since no keypoint would have accounted for it, wrist flexion and deviation were locked at 0°, and arm pronation/supination was locked at 90°. Conversely, the translation of the pelvis was unlocked, in addition to the subtalar angle; and hip flexion was limited to 150° instead of 120° (which was not enough for the pedaling task). With regards to the previous chapter, marker placement was also improved in the OpenSim model. The average systematic offset between OpenPose-triangulated keypoints and MoCap-calculated joint centers was measured on our 3D overlay view (Figure~\ref{fig_mkmkl}), and was taken into account when manually placing OpenPose keypoints onto the OpenSim unscaled model.

OpenSim (version 4.2) was used to scale the model to the participant on a T-pose, and then inverse kinematics was performed. Scale factors were computed with measurement-based scaling, i.e., by computing the ratio of distances between keypoints on the model, and experimental keypoints provided by the coordinates file of triangulated OpenPose data. Static pose weights were all set to 1, apart from Nose and Head keypoints which were set to 0.1, and Shoulder and Hip keypoints were set to 2. The participant was standing upright with feet flat during his T-pose, so we set a weight of 1 for a zero angle in pelvis list, pelvis tilt, L5-S1 flexion, and ankle angles. The offset in machine-learning-based joint center estimations has been shown to be systematic and not dependent on the subject \cite{Needham2021b} (nor on the operator); hence, once this bias has been taken into account in the generic model, the markers’ adjustment step is unnecessary. Keypoint weight markers for inverse kinematics were the same as for scaling.


\subsection{Marker-based analysis}

The captured markers were automatically identified with an AIM procedure within the Qualisys Track Manager software (version 2019.1). Joint centers were then calculated. The centers of ankles, knees, wrists, and elbows were defined as the midpoints between the malleoli/epicondyles/styloids since it has been shown that when executed on a lean participant, functional methods do not improve the reliability of the kinematics of running \cite{Pohl2010}. Hip joint center was defined with a functional method \cite{Halvorsen2003}. The OpenSim model used for marker-based scaling and inverse kinematics was the same as the Pose2Sim model. Scale factors were computed similarly, but with marker data rather than with OpenPose keypoints. Weights proposed by the inverse kinematics solver of OpenSim were set to 5 for joint centers, to 1 for cluster markers, and to 2 for other anatomical markers. Inverse kinematics was processed with the same marker weights.


\subsection{Statistical analysis} \label{stats_accuracy}

Since the participant did not report any locomotion impairment and the captured movements were mostly symmetrical, we only analyzed the right side. Our study focuses on the lower limb, but results for upper limb and sacro-lumbar joints are detailed in the \hyperref[Ann:2]{Appendix B} for information (Figure~\ref{fig_qtmwalkup} and Figure~\ref{fig_blandwalkup} for walking, Figure~\ref{fig_qtmrunup} and Figure~\ref{fig_blandrunup} for running, and Figure~\ref{fig_qtmbikeup} and Figure~\ref{fig_blandbikeup} for cycling). The analyzed angles were ankle flexion/extension, subtalar angle, knee flexion/extension, and hip flexion/extension, abduction/adduction, and internal/external rotation provided by the OpenSim inverse kinematics procedure.

First, Pose2Sim scale factors were compared to marker-based ones, and RMS errors were reported and compared to OpenSim’s best practice rules. Then, the overall similarity of paired angle waveforms was assessed with a special formulation of the coefficient of multiple correlation (CMC), specifically designed to compare different protocols or measurement systems \cite{Ferrari2010}. The CMC gives a single result taking into account differences in correlation, gain, and offset. It reaches 1 if the curves are perfectly overlapped, and drops to zero if the curves are very dissimilar, or even to complex values (reported as "nan" hereafter). This is, for example, the case if the mean inter-protocol offset (averaged over time and trials) exceeds the grand mean ROM, which results in taking the square root of a negative number. CMC values are deemed good if between 0.75 and 0.84, very good if between 0.85 and 0.94, and excellent if above 0.95 \cite{Ferrari2010}. The CMC results were then broken down to take an in-depth look into correlation, gain, and offset, separately. The strength of the linear relationship between kinematic analysis systems was assessed with the Pearson’s r correlation coefficient. Gain was evaluated by computing the paired ROM differences. Once normality of the ROM errors was checked with a Shapiro–Wilk test \cite{Shapiro1965}, we computed paired t-tests to verify whether the error was significant \cite{Student1908}. Mean inter-protocol offset angle, hereafter called mean error, was one of the outputs of the subsequent Bland–Altman analysis \cite{Bland1986,Atkinson1998}. Once normality of the paired means of the angle differences was verified, we determined if the mean markerless angles were significantly different to the mean marker-based ones.

The Bland–Altman analysis gives some more information about the agreement between the considered markerless and marker-based systems \cite{Bland1986,Atkinson1998}. It consists of plotting the difference between the values given by both systems against their mean, for all angular points at all time instances. Limits of agreement were defined as the interval within which 95\% of data will be found, i.e., between mean difference ±1.96 standard deviation, provided that the differences follow a normal distribution. Bland–Altman plots also help to identify the potential presence of heteroscedasticity, i.e., the fact that the spread of the error may depend on the angle magnitude \cite{Atkinson1998}.

Finally, root-mean-square errors (RMSE), mean errors (\(Mean_{err}\)), and ROM errors (\(ROM_{err}\)) were computed for the walking task to enable comparison with previously published metrics obtained using Theia3D, a commercial markerless solution \cite{Kanko2021b}, and Xsens \cite{Zhang2013}, a commercial system based on IMUs. Theia3D’s ROM results were approximated from reported graphics along the flexion/extension degree of freedom.


\section{Results}

\subsection{Concurrent validation}

Inverse kinematics is successful when OpenSim’s global optimizer keeps the model markers close to experimental markers, i.e., when RMSE is less than 2–4 cm according to OpenSim’s best practices. This was the case for both systems (Table~\ref{table:rmse_opensim}). However, RMSE was particularly higher in cycling than in walking or running.

\begin{table}[!ht]
      \centering
      \begin{tabular}{lll}
          \toprule
          \textbf{Task} & \shortstack{\textbf{Marker-based} \\\textbf{RMSE (cm)}} & \shortstack{\textbf{Markerless} \\\textbf{RMSE (cm)}}\\ 
          \specialrule{0.14 em}{0pc}{0pc}
          Walking & 1.1—1.2 & 1.4—1.9 \\ 
          Running & 1.5—1.7 & 1.5—2.1 \\ 
          Cycling & $\approx$ 3.5 & 3.0—3.6 \\ 
          \bottomrule
      \end{tabular}
      \caption{RMSE between experimental and theoretical markers during OpenSim inverse kinematics, for both marker-based and Pose2Sim models.}
        \label{table:rmse_opensim}
  \end{table}

CMC assesses waveform similarities between Pose2Sim and the marker-based reference method, by jointly evaluating correlation, gain, and offset. It was mostly very good (CMC > 0.85) to excellent (CMC > 0.95) in all tasks, all degrees of freedom, and all lower-body joints (Table~\ref{table:tab_mkcomp}, Figure~\ref{fig_qtmwalk}, Figure~\ref{fig_qtmrun}, and Figure~\ref{fig_qtmbike}). This was especially the case along the flexion/extension degree of freedom, except for angles of the hip in running and of the ankle in cycling, for which CMC results suffered from an offset compared to the marker-based method. Hip abduction/adduction and internal/external rotation waveforms were not in good agreement (CMC < 0.75), except for the hip internal/external rotation angles in running. In cycling, all non-sagittal angles had complex CMCs, which means that no agreement was found at all.

\clearpage

\begin{figure}[!ht]
	\centering
	\def\svgwidth{1\columnwidth}
	\fontsize{10pt}{10pt}\selectfont
	\includegraphics[height=\dimexpr\textheight-100pt]{"../Chap5/Figures/Fig_QTMWalk.png"}
	\caption{Pose2Sim (cyan) and marker-based (black) lower-body joint angles for the walking task. Coefficient of multiple correlation (CMC) is indicated, and broken down into, respectively, Pearson’s coefficient (r) for correlation assessment, range of motion errors (\(ROM_{err}\)) for gain, and overall mean errors (\(Mean_{err}\)) for offset. Mean error and standard deviations are also represented at the bottom of the graphics. See \hyperref[Ann:2]{Appendix B} for running and cycling results, and for sacro-lumbar and upper-body results. }
	\label{fig_qtmwalk}
\end{figure}

\clearpage

\begin{table}[!ht]
      \resizebox{\textwidth}{!}{
      \centering
      \begin{tabular}{llllllllllllll}
          \toprule
              \multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Joint}} & \multicolumn{4}{c}{\textbf{ Flex./Ext.}} & \multicolumn{4}{c}{\textbf{Abd./Add.}$^1$} & \multicolumn{4}{c}{\textbf{Int./Ext. rot.}}\\ 
                  \cmidrule(l{2pt}r{2pt}){3-6}\cmidrule(l{2pt}r{2pt}){7-10}\cmidrule(l{2pt}r{2pt}){11-14}
                  ~ & ~ &  CMC & r & \(\mathrm{ROM_{err}}\) & \(\mathrm{Mean_{err}}\) & CMC & r & \(\mathrm{ROM_{err}}\) & \(\mathrm{Mean_{err}}\) & CMC & r & \(\mathrm{ROM_{err}}\) & \(\mathrm{Mean_{err}}\) \\ 
                  \specialrule{0.14 em}{0pc}{0pc}
                  \multirow{3}{*}{Walking} & Ankle	& 0.90 &	0.89&	-1.22&	-2.79*&	0.86&	0.85&	6.48*&	2.56*&	—& 	—& 	—& 	— \\
                  &	Knee& 0.98 & 0.96 & -0.30 & -1.92* 	& —& —& —& —& —& —& —& —\\
                  &	Hip& 0.96 & 0.96 & -1.70 & -3.04* & 0.74 & 0.81 & -1.81* & -2.6* & 0.34 & 0.54 & 4.68* & -5.27*	\\
                  \midrule
                  \multirow{3}{*}{Running} & Ankle	& 0.99 &	0.99&	-2.9*&	-0.71* &	0.97 &	0.96& 2.20 & 0.96 & —& 	—& 	—& 	— 	\\
                    &Knee & 1.00 & 1.00 & 0.04 & -0.65*  	& —& —& —& —& —& —& —& —	\\
                    &Hip& 0.65 & 0.95 & 4.01* & 15.18* & 0.37 & 0.65 & -3.94* & -3.76* & 0.93 & 0.95 & 1.25 & -3.49*	\\
                  \midrule
                  \multirow{3}{*}{Cycling} & Ankle	& 0.75 & 0.85 & 1.93* & -6.73& nan & -0.32 & 10.27* & 1.59* & —& 	—& 	—& 	— \\
                    &Knee&	1.00 & 1.00 & -2.94* & 2.12* 	& —& —& —& —& —& —& —& —\\
                    &Hip& 0.92 & 0.97 & -5.91* & 6.12* & nan & 0.14 & 1.72* & -5.62* & nan & -0.07 & 3.07* & 2.11*	\\
          \bottomrule
      \end{tabular}}
      \caption{Summary of comparisons between Pose2Sim and marker-based angle waveforms. A specific formulation of the Coefficient of Multiple Correlation (CMC) was used, specifically designed to compare different protocols or measurement systems. CMC jointly evaluates correlation, gain, and offset, which were respectively assessed with r-Pearson's coefficient, range of motion errors (\(ROM_{err}\)), and mean errors (\(Mean_{err}\)). *Significant at 5\% level. $^1$Despite ankle subtalar angle combines abduction/adduction and internal/external rotation, it is thereafter reported in the abduction/adduction column. }
        \label{table:tab_mkcomp}
  \end{table}

  Pearson’s r correlation coefficient results were close to the CMC ones, albeit they became very good to excellent in the two angles that were affected by an offset. When averaged over all joint angles, errors in the range of motion (\(ROM_{err}\)) were 2.7° (sd = 2.1°), 2.3° (sd = 1.1°), and 4.3° (sd = 2.5°) in walking, running, and cycling, respectively. Along the flexion/extension degree of freedom, they were below 2°, 4°, and 6°, in walking, running, and cycling, respectively. Along the internal/external rotation degree of freedom, they stayed below 5°; however, they reached up to 10° along the abduction/adduction degree of freedom. Average mean angle errors (\(Mean_{err}\)) were 3.0° (sd = 1.0°), 4.1° (sd = 1.6°), and 4.0° (sd = 0.59°), in walking, running, and cycling, respectively. In walking and running, mean errors remained under 5.3° in all degrees of freedom, apart from the hip flexion/extension angle in running, which was offset by 15°. Although they were noticeably larger, mean errors were always under 7° in cycling  (Table~\ref{table:tab_mkcomp} and Table~\ref{table:tab_bland}, Figure~\ref{fig_qtmwalk}, Figure~\ref{fig_qtmrun}, and Figure~\ref{fig_qtmbike})
    
  \begin{table}[!ht]
      \centering
      \resizebox{0.73\textwidth}{!}{
      \begin{tabular}{llllllll}
          \toprule
              \multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Joint}} & \multicolumn{2}{c}{\textbf{ Flex./Ext.}} & \multicolumn{2}{c}{\textbf{Abd./Add.*}} & \multicolumn{2}{c}{\textbf{Int./Ext. rot.}}\\ 
                  \cmidrule(l{2pt}r{2pt}){3-4}\cmidrule(l{2pt}r{2pt}){5-6}\cmidrule(l{2pt}r{2pt}){7-8}
                  ~ & ~ & \(\mathrm{Mean_{err}}\) (°) & 95\% LoA (°) & \(\mathrm{Mean_{err}}\) (°) & 95\% LoA (°) & \(\mathrm{Mean_{err}}\) (°) & 95\% LoA (°) \\ 
                  \specialrule{0.14 em}{0pc}{0pc}
                  \multirow{3}{*}{Walking} & Ankle	& -2.79 &	[-9.4,3.8]&	2.56&	[-6.9,12]&	 	—& 	— \\
                  &	Knee& -1.92 & [-12,8.4] 	& —& —& —& —\\
                  &	Hip& -3.04 & [-11,5.2]& -2.6 & [-6.9,1.7] & -5.27 & [-14,3.5]	\\
                  \midrule
                  \multirow{3}{*}{Running} & Ankle&	-0.71   & [-4.5,3.0] & 0.96 & [-5.3,7.2] & —& 	— \\
                    &Knee & -0.65 & [-2.9,1.6] & —& —& —& —\\
                    &Hip& 15.18 & [5.5,25] & -3.76 & [-9.2,1.6] & -3.49 & [-9.3,2.4]	\\
                  \midrule
                  \multirow{3}{*}{Cycling} & Ankle& -6.73 & [-16,2.1] & 1.59 & [-9.8,13] & —& 	— \\
                    &Knee&	2.12 & [-1.1,5.3] & —& —& —& —\\
                    &Hip& 6.12 & [-1.7,14] & -5.62 & [-10,-1.1] & 2.11 & [-4.5,8.7]\\
          \bottomrule
      \end{tabular}}
      \caption{Bland–Altman analysis results of 3D angle errors between Pose2Sim analysis and the reference marker-based one. Mean errors (\(Mean_{err}\)) and 95\% limits of agreement (LoA) are represented. *Although ankle subtalar angle combines abduction/adduction and internal/external rotation, it is hereafter reported in the abduction/adduction column.}
        \label{table:tab_bland}
  \end{table}

Limits of Agreement (LoA) values were relatively evenly and randomly distributed among all tasks, degrees of freedom, and joints, averaging to an interval of 15° within which 95\% of the errors would lie (Table~\ref{table:tab_bland}, Figure~\ref{fig_blandwalk}, Figure~\ref{fig_blandrun}, and Figure~\ref{fig_blandbike}). Due to the limited range of motion of sacro-lumbar and upper-body angles, limits of agreement were smaller in these joint angles (Figure~\ref{fig_blandwalkup}, Figure~\ref{fig_blandrunup}, and Figure~\ref{fig_blandbikeup}). Angle magnitude did not have an influence on the spread of errors (hence the data are homoscedastic), except for the cycling task for ankle angles and flexion/extension hip angles.

\begin{figure}[!ht]
	\centering
	\def\svgwidth{1\columnwidth}
	\fontsize{10pt}{10pt}\selectfont
	\includegraphics[width=0.97\linewidth]{"../Chap5/Figures/Fig_BlandWalk.png"}
	\caption{Bland–Altman analysis of lower-body joint angle errors for the walking task. Mean bias is represented as a horizontal solid, bold line, and 95\% limits of agreement are represented as dotted lines. See \hyperref[Ann:2]{Appendix B} for running and cycling results, and for sacro-lumbar and upper-body results.}
	\label{fig_blandwalk}
\end{figure}

\clearpage 

\subsection{Comparison with other systems}

The RMSE reported by Theia3D \cite{Kanko2021b} was, on average, 1.5° higher than that of Pose2Sim, and its ROM errors were consistently higher, at least along the flexion/extension degree of freedom. However, the study using Xsens \cite{Zhang2013} reported mean errors 0.3° lower on average, and ROM errors 1.0° lower on average (Table~\ref{table:tab_theiaxsens}).

\begin{table}[!ht]
      \centering
      \resizebox{0.8\textwidth}{!}{
      \begin{tabular}{lllllllllll}
          \toprule
              \multirow{2}{*}{\shortstack{\textbf{Error}\\ \textbf{metric}}} & \multirow{2}{*}{\textbf{Joint}} & \multicolumn{3}{c}{\textbf{ Flex./Ext.}} & \multicolumn{3}{c}{\textbf{Abd./Add.}} & \multicolumn{3}{c}{\textbf{Int./Ext. rot.}}\\ 
                  \cmidrule(l{2pt}r{2pt}){3-5}\cmidrule(l{2pt}r{2pt}){6-8}\cmidrule(l{2pt}r{2pt}){9-11}
                  ~ & ~ &  \textbf{Ours} & Theia  & Xsens  &  \textbf{Ours} & Theia & Xsens &  \textbf{Ours} & Theia & Xsens \\ 
                  \specialrule{0.14 em}{0pc}{0pc}
                  \multirow{3}{*}{RMSE (°)} & Ankle	& 4 & 6.7 & — & 5.1 & 8 & — & — & — & —\\
                  &	Knee&5.1 & 3.3 & — & — & — & — & — & — & — \\
                  &	Hip& 5.6 & 11 & — & 3.1 & 2.6 & — & 6.6 & 6.9 & — \\
                  \midrule
                  \multirow{3}{*}{Mean\(_{err}\) (°)} & Ankle	& 2.79 & — & 2.15 & 2.56 & — & 1.81 & — & — & — \\
                    &Knee&	1.92 & — & 1.87 & — & — & — & — & — & — \\
                    &	Hip&3.04 & — & 2.47 & 2.6 & — & 4.83 & 5.27 & — & 3.02 \\
                    \midrule
                  \multirow{3}{*}{ROM\(_{err}\) (°)} & Ankle	& -1.22 & $\approx$ -10 & 0.4 & 6.48 & — & 1.38 & — & — & — \\
                    &Knee& -0.3 & $\approx$ -1 & 0.8 & — & — & — & — & — & — \\
                    &	Hip& -1.7 & $\approx$ -10 & 2.42 & -1.81 & — & 5.37 & 4.68 & — & 0.04 \\
          \bottomrule
      \end{tabular}}
      \caption{Pose2Sim results compared to Theia3D \cite{Kanko2021b} and to Xsens \cite{Zhang2013} in the walking task. Root-mean-square error (RMSE), mean error (Meanerr), and range of motion (ROM) are examined. Theia3D’s ROM results were approximated from reported graphics along the flexion/extension degree of freedom. Both studies to which we compared our results involved a different setup (participants, cameras, protocol, etc.), therefore the differences cannot be totally attributed to the different technologies (markerless or IMU) nor to the different algorithm (Pose2Sim or Theia3D). * Although ankle subtalar angle combines abduction/adduction and internal/external rotation, it is hereafter reported in the abduction/adduction column.}
      \label{table:tab_theiaxsens}
\end{table}


\section{Discussion}

\subsection{Strengths of Pose2Sim and of markerless kinematic}

Pose2Sim offers a way to perform a markerless kinematic analysis from multiple calibrated views, taking OpenPose results as inputs, and giving biomechanically oriented results via OpenSim. Both OpenPose and OpenSim are open-source and among the most widespread and renowned tools in their respective fields. We compared Pose2Sim lower-body results to those of a reference marker-based method, over three tasks performed by one participant: walking, running, and cycling. Both protocols were as similar as possible, and used the same constrained skeletal model in order to ensure that there was no discrepancy in results caused by different definitions of anatomical frames \cite{Croce1999}. Pose2Sim kinematic waveforms were very similar to marker-based ones, especially in the sagittal plane. One exception to this observation was the hip angle in running, which suffered from a 15° offset due to the dearth of keypoints in this area. This led the optimization procedure to admit two solutions for the spine curvature, both mathematically and kinematically correct: one with a lordotic posture, and the other with a kyphotic posture. There was also less agreement for ankle angles in cycling, most likely because for both Pose2Sim and marker-based kinematics, keypoint/marker detections suffered from occlusions from the bike. This is corroborated by the higher RMSE between experimental and theoretical markers observed in cycling (Table~\ref{table:rmse_opensim}). The similarity of waveforms among both protocols was assessed with the coefficient of multiple correlation (CMC) \cite{Ferrari2010}, which takes into account the concurrent effects of correlation, gain, and offset. When averaged over all lower-limb joints and all degrees of freedom, mean errors amounted to 3.0°, 4.1°, and 4.1° in walking, running, and cycling, respectively, and range of motion errors were equal to 2°, 2.3°, and 4.3°. It should be noted that, unlike ours, Theia3D \cite{Kanko2021b} and Xsens \cite{Zhang2013} studies to which we compared our results involved several subjects (30 and 10, respectively.) Our study recorded with eight virtual cameras, 1 MP definition, 30 Hz framerate, and perfect calibration, whereas the Theia system recorded with eight cameras, 3 MP definition, 85 Hz, with a marker-based calibration. Hence, the comparison between accuracies of Theia3D, Xsens and Pose2Sim are given for an overview of their order of magnitude, not as a claim for exact comparison. This study focused on lower-body kinematics, however we also reported upper-body and sacro-lumbar kinematics in \hyperref[Ann:2]{Appendix B} for reference. It may be noted that differences between the two approaches were larger than for the lower body, and especially for the sacro-lumbar flexion.

This shows that a carefully designed skeletal model, when correctly scaled and constrained, can lead to accurate results from a markerless approach, despite poorly labeled joint centers \cite{Needham2021b, Wade2021}, and despite a low number of detected keypoints. Indeed, it has been shown that the triangulation of deep-learning-based pose estimation methods produces systematic errors up to 50 mm in 3D knee and hip joint center coordinates \cite{Needham2021b}. Without the use of a skeletal model, flexion/extension lower-body angle errors in cycling have been demonstrated to be as large as 3–12° \cite{Bini2021}. Moreover, Pose2Sim still gave relevant results when using the coordinates of only 21 triangulated keypoints coordinates (after exclusion of eye and ear keypoints). This is in line with conclusions that were previously made for marker-based approaches, implying that constrained kinematic models are resilient to marker placement and quantity \cite{Slater2018}.

The setup of Pose2Sim can be installed anywhere, i.e., directly on-site rather than in a laboratory setting. No particular attention has to be devoted to the background color, to the participant’s clothing, nor to the luminance of the recording area. No apparatus interferes with the athlete’s movement, who can fully concentrate on their performance. This is of crucial importance in the context of sports analysis. Results are not operator or subject dependent, which makes labeling, scaling, and inverse kinematics both easy and robust. It is to be noted, however, that it does not leave room for adjustment if it is needed to better monitor a specific body part. However, the operator or scientist has access to fine control on most parameters at each step of the analysis: the deep-learning 2D pose estimation model can be changed; tracking, triangulation, and filtering parameters can be adjusted; and the OpenSim model, scaling, and inverse kinematics can be entirely controlled.


\subsection{Limits and perspectives}

Our study still has potential limitations, starting with those stated in the previous chapter on \nameref{ch:4}: we used a virtual scene, 

Both systems were neither cross-calibrated nor synchronized by hardware. Concerning calibration,we were only looking for relative joint angles, thus sharing common coordinates was not important. Concerning the second issue, we visually synchronized the data to the frame on a sharp movement. However, our framerate was only 30 fps, which means that there could be up to a half frame (1/15 seconds) of delay. Moreover, gait events were calculated with a kinematic approach \cite{Zeni2008} rather than detected with a force plate. And yet, all of these limits would have likely deteriorated our results rather than artificially improved them. 

On the other hand, our study was conducted on a limited amount of data: only 8–13 cycles per task were captured, performed by one participant, and captured at 30 Hz. Given the relatively slow and steady movements we analyzed, we believe that this framerate did not impact our results, although both marker-based and markerless kinematics would beneficiate from a higher sample frequency on more demanding activities. Note that Pose2Sim can operate at any framerate, and this limitation is only due to the settings of the video acquisition system. Although results cannot be overly generalized to other sports movements, we assume that conclusions would hold for other healthy subjects, first because the OpenPose training was done on numerous participants having different gender, race, body shape, and outfit \cite{Andriluka2014,Lin2014,Xiang2019}; second, because deep-learning-based pose estimation algorithms are not subject to inter-operator errors nor to soft-tissue artifacts; and, third, because the OpenSim kinematic model is scaled to the participant’s anthropometry. Nonetheless, it would be worth assessing its accuracy on more challenging sports and with multiple subjects. Moreover, we used perfect virtual cameras instead of real ones. Real cameras could have induced errors due to motion blur, large distortions, or calibration errors. Our previous study, however, showed that the system was very robust to these issues, including with as little as four cameras, at least with movements such as walking, running, and cycling on an ergometer (see previous chapter on \nameref{ch:4} \cite{Pagnon2021}). It may be interesting to try Pose2Sim with light and versatile action cameras such as GoPros, calibrated with a checkerboard. The accuracy of these cameras has already been explored on marker-based data. Although the maximum point coordinate error was about 10 times as large as that with a motion capture system (2.47 versus 0.21 mm), knee joint angles were highly correlated (joint coordinates error below 2.5°) \cite{Dalla2019}. This is the topic of the next chapter, about hyperref[ch:6]{GoPros used for boxing analysis}.

OpenPose keypoint localization suffers from systematic offsets when compared to actual joint center positions \cite{Needham2021b}. This has been taken into account on a static pose in the OpenSim unscaled model, by shifting OpenPose keypoint placements with regard to marker-based joint centers. This was done manually, but precisely, due to our overlayed view (Figure~\ref{fig_mkmkl}). The OpenSim model was then scaled to the participant’s anatomy without the use of any MoCap procedure. However, OpenPose’s offset may not be the same when a limb is extended as when it is bent, which may influence kinematic results on extreme poses. Hence, using a pose estimation model free from systematic biases on all ranges of motion would improve kinematic accuracy, even if applying a constrained skeletal model already largely reduces the detrimental impact of low-quality 2D joint center estimations. See \autoref{ch:3} on Pose2Sim for more details on perspectives.

\cite{Desmarais2021} proposed a taxonomy of 3D pose estimation algorithms based on accuracy, robustness, and speed. Accuracy was assessed in this chapter, and robustness was investigated in the previous one; however, speed has not yet been tested. Yet, a timely feedback is crucial for coaches and athletes to be able to use a motion analysis software. The bottleneck for computational costs, here, is by far the pose estimation system, but some neural networks are tackling this issue \cite{Bazarevsky2020, Wang2022a}.

Deep-learning-based human pose estimation is making considerable and consistent progress. It is becoming more accurate, more robust, faster, and simpler to use, approaching Atha’s 1984 definition of an ideal motion analysis system \cite{Atha1984}. Pose2Sim takes advantage of these advances, and mitigates the remaining errors by constraining these outputs to obtain physically consistent kinematics.